{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg1xrUfPex1i"
      },
      "outputs": [],
      "source": [
        "!pip install pymc==5.10.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Tg3_S8PfRBb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOtBGuBtfU6l"
      },
      "outputs": [],
      "source": [
        "# load training dataset into df_winter by replacing the path to the dataset below\n",
        "df_winter = pd.read_csv('',index_col=0, parse_dates=True)\n",
        "\n",
        "df_winter.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ3zQExWfk2o"
      },
      "outputs": [],
      "source": [
        "df_winter.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWU8FLdvgRHP"
      },
      "outputs": [],
      "source": [
        "df_winter = df_winter.dropna()\n",
        "df_winter_val = df_winter_val.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4BFp80GgXu4"
      },
      "outputs": [],
      "source": [
        "df_winter.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UO3_VvwggLg"
      },
      "outputs": [],
      "source": [
        "df_winter['fog_index_6h'].eq(0).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTaEzPrUgn4w"
      },
      "outputs": [],
      "source": [
        "df_winter.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpdElnH1g6Cp"
      },
      "outputs": [],
      "source": [
        "df_filtered = df_winter[df_winter['fog_index_6h'] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2xNoAmqhUfb"
      },
      "outputs": [],
      "source": [
        "df_winter = df_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3LkEv0ShX-A"
      },
      "outputs": [],
      "source": [
        "df_winter.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpPHv431hczA"
      },
      "outputs": [],
      "source": [
        "df_winter['fog_index_6h'].eq(0).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L515u5FQkZq8"
      },
      "outputs": [],
      "source": [
        "df_winter['energy_loss'].eq(0).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywe43AD9koCg"
      },
      "outputs": [],
      "source": [
        "df_winter['fog_duration'].eq(0).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_n5p9a_k-DI"
      },
      "outputs": [],
      "source": [
        "df_winter['fog_month'].eq(0).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5F_IYTVxlJjC"
      },
      "outputs": [],
      "source": [
        "df_winter['fog_index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeiAqQcrJxUD"
      },
      "outputs": [],
      "source": [
        "df_winter = df_winter[df_winter['energy_loss'] <= 1500000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmSoidTo50h3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7HiopS-53nb"
      },
      "outputs": [],
      "source": [
        "\n",
        "X = df_winter.drop([\"fog_index_6h\"], axis=1)  # Features\n",
        "y = df_winter[\"fog_index_6h\"]  # Target variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn_1iv-H4p8L"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bbl06P7HhyfI"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X)  # Fit scaler on training data\n",
        "\n",
        "X_train_scaled = scaler.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ6mfJPZh1lP"
      },
      "outputs": [],
      "source": [
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnIIIC4kh514"
      },
      "outputs": [],
      "source": [
        "X_train_scaled_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvOIE8p3SUMt"
      },
      "outputs": [],
      "source": [
        "X_train_scaled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhpr-SUASdev"
      },
      "outputs": [],
      "source": [
        "y_train = y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjDuxR4Gh9WP"
      },
      "outputs": [],
      "source": [
        "import pymc as pm\n",
        "\n",
        "with pm.Model() as beta_regression_model:\n",
        "    # Priors\n",
        "    beta_0 = pm.Normal('beta_0', mu=0, sigma=100)\n",
        "    beta_1 = pm.Normal('beta_1', mu=0, sigma=100)\n",
        "    beta_2 = pm.Normal('beta_2', mu=0, sigma=100)\n",
        "    beta_3 = pm.Normal('beta_3', mu=0, sigma=100)\n",
        "    beta_4 = pm.Normal('beta_4', mu=0, sigma=100)\n",
        "    beta_5 = pm.Normal('beta_5', mu=0, sigma=100)\n",
        "    beta_6 = pm.Normal('beta_6', mu=0, sigma=100)\n",
        "    beta_7 = pm.Normal('beta_7', mu=0, sigma=100)\n",
        "    beta_8 = pm.Normal('beta_8', mu=0, sigma=100)\n",
        "\n",
        "    avg_air_temp = pm.MutableData('avg_air_temp', X_train_scaled_df['avg_air_temp'])\n",
        "    avg_dew_point = pm.MutableData('avg_dew_point', X_train_scaled_df['avg_dew_point'])\n",
        "    avg_relative_humidity = pm.MutableData('avg_relative_humidity', X_train_scaled_df['avg_relative_humidity'])\n",
        "    avg_pressure = pm.MutableData('avg_pressure', X_train_scaled_df['avg_pressure'])\n",
        "    avg_visibility = pm.MutableData('avg_visibility', X_train_scaled_df['avg_visibility'])\n",
        "    energy_loss = pm.MutableData('energy_loss', X_train_scaled_df['energy_loss'])\n",
        "    fog_duration = pm.MutableData('fog_duration', X_train_scaled_df['fog_duration'])\n",
        "    fog_month = pm.MutableData('fog_month', X_train_scaled_df['fog_month'])\n",
        "\n",
        "    fog_index_6h = pm.MutableData('fog_index', y_train)\n",
        "\n",
        "    alpha = pm.Uniform('alpha', lower=0, upper=200)\n",
        "    beta = pm.Uniform('beta', lower=0, upper=200)\n",
        "\n",
        "    # Precision parameterization\n",
        "    phi = alpha + beta\n",
        "\n",
        "\n",
        "    # Mean of the beta distribution\n",
        "    mu = pm.Deterministic('mu', pm.math.invlogit( beta_0 + beta_1 * avg_air_temp +\n",
        "                          beta_2 * avg_dew_point +\n",
        "                          beta_3 * avg_relative_humidity +\n",
        "                          beta_4 * avg_pressure +\n",
        "                          beta_5 * avg_visibility +\n",
        "                          beta_6 * energy_loss +\n",
        "                          beta_7 * fog_duration +\n",
        "                          beta_8 * fog_month\n",
        "                          ))\n",
        "\n",
        "    # Likelihood\n",
        "    fog_index_var = pm.Beta('fog_index_var', alpha=mu * phi, beta=(1 - mu) * phi, observed=fog_index_6h)\n",
        "\n",
        "    # Inference\n",
        "    trace = pm.sample(draws=2000, tune=2000, chains=2,return_inferencedata=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-TZvSI76uba"
      },
      "outputs": [],
      "source": [
        "import arviz as az\n",
        "az.plot_trace(trace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pCJa7CLAnOF"
      },
      "outputs": [],
      "source": [
        "az.summary(trace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GRMrX8dh7Of"
      },
      "outputs": [],
      "source": [
        "!pip install dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx_3unUahyLB"
      },
      "outputs": [],
      "source": [
        "import dill  # Or import cloudpickle\n",
        "\n",
        "with open('/content/drive/MyDrive/A_fog_index/beta_model.pkl', 'wb') as buff:\n",
        "     dill.dump({'model': beta_regression_model, 'trace': trace}, buff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiJ3vK6iBFZ4"
      },
      "outputs": [],
      "source": [
        "import arviz as az\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLeodHz6BKNX"
      },
      "outputs": [],
      "source": [
        "with beta_regression_model:  # Reuse the model context\n",
        "    ppd = pm.sample_posterior_predictive(\n",
        "        trace,\n",
        "        var_names=['mu','fog_index_var'],  # Name of your output variable\n",
        "        random_seed=42  # Optional, set a seed for reproducibility\n",
        "    )\n",
        "    az.plot_ppc(ppd)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFp8BdVYBoE3"
      },
      "outputs": [],
      "source": [
        "trace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCEmJ9ISBpoS"
      },
      "outputs": [],
      "source": [
        "ppd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjCVUY04U2Nx"
      },
      "outputs": [],
      "source": [
        "## load validation dataset into df_winter_val by updating the path below\n",
        "\n",
        "df_winter_val = pd.read_csv('',index_col=0, parse_dates=True)\n",
        "\n",
        "df_winter_val = df_winter_val.dropna()\n",
        "\n",
        "# df_filtered_val = df_winter[df_winter['fog_index_6h'] != 0]\n",
        "\n",
        "X_val = df_winter_val.drop([\"fog_index_6h\"], axis=1)  # Features\n",
        "y_val = df_winter_val[\"fog_index_6h\"]  # Target variable\n",
        "\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=X_val.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADxRuIHXBtPT"
      },
      "outputs": [],
      "source": [
        "with beta_regression_model:\n",
        "    pm.set_data({\n",
        "        'avg_air_temp': X_val_scaled_df['avg_air_temp'],\n",
        "        'avg_dew_point': X_val_scaled_df['avg_dew_point'],\n",
        "        'avg_relative_humidity': X_val_scaled_df['avg_relative_humidity'],\n",
        "        'avg_pressure': X_val_scaled_df['avg_pressure'],\n",
        "        'avg_visibility': X_val_scaled_df['avg_visibility'],\n",
        "        'energy_loss': X_val_scaled_df['energy_loss'],\n",
        "        'fog_duration': X_val_scaled_df['fog_duration'],\n",
        "        'fog_month': X_val_scaled_df['fog_month'],\n",
        "        'fog_index': y_val\n",
        "    })\n",
        "\n",
        "    idata_val = pm.sample_posterior_predictive(\n",
        "                trace,\n",
        "                var_names=[\"mu\",\"fog_index_var\"],\n",
        "                return_inferencedata=True,\n",
        "                predictions=True,\n",
        "                extend_inferencedata=True,\n",
        "                random_seed=42  # Or any seed\n",
        "     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvMk6u0wB3Rw"
      },
      "outputs": [],
      "source": [
        "idata_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0OBF2UpB5LL"
      },
      "outputs": [],
      "source": [
        "print(idata_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X7qWCGpB8qe"
      },
      "outputs": [],
      "source": [
        "print(idata_val.predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElyxQ2EhCORG"
      },
      "outputs": [],
      "source": [
        "predictions_for_val_point = idata_val.predictions['fog_index_var']  # Sample some draws\n",
        "\n",
        "# HDI Calculation\n",
        "hdi = pm.hdi(predictions_for_val_point, hdi_prob=0.95)\n",
        "print(hdi)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_point_predictions_mean = idata_val.predictions['fog_index_var'].mean(dim=['chain', 'draw']).values\n",
        "val_point_predictions_median = idata_val.predictions['fog_index_var'].median(dim=['chain', 'draw']).values"
      ],
      "metadata": {
        "id": "_jmTTfAOOi7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_intervals(hdi,y_test,pp_mean,pp_median):\n",
        "  test_lower_bounds = []\n",
        "  test_upper_bounds = []\n",
        "  test_original_values = []\n",
        "  test_point_pred_mean = []\n",
        "  test_point_pred_median =[]\n",
        "  test_lower_upper_avg = []\n",
        "  test_dates = []\n",
        "\n",
        "  for idx in range(len(hdi['fog_index_var_dim_2'])):\n",
        "    lower_bound = hdi.sel(fog_index_var_dim_2=idx, hdi='lower')['fog_index_var'].values\n",
        "    upper_bound = hdi.sel(fog_index_var_dim_2=idx, hdi='higher')['fog_index_var'].values\n",
        "    avg = (upper_bound - lower_bound)/2\n",
        "\n",
        "    # print(lower_bound['fog_index_var'].values)\n",
        "\n",
        "    point_pred_mean = pp_mean[idx]\n",
        "    point_pred_median = pp_median[idx]\n",
        "    # lb = lower_bound['fog_index_var'].values\n",
        "    # ub = upper_bound['fog_index_var'].values\n",
        "    # break\n",
        "    original = y_test[idx]\n",
        "    date = y_test.index[idx]\n",
        "    # print(f\"Test Point: {idx}, Range: ({lower_bound:.2f}, {upper_bound:.2f}) ,point mean: {point_pred_mean:.2f},point median: {point_pred_median:.2f}, Original: {original:.2f}, Date: {date}\")\n",
        "    test_lower_bounds.append(lower_bound)\n",
        "    test_upper_bounds.append(upper_bound)\n",
        "    test_point_pred_mean.append(point_pred_mean)\n",
        "    test_point_pred_median.append(point_pred_median)\n",
        "    test_lower_upper_avg.append(avg)\n",
        "    test_original_values.append(original)\n",
        "    test_dates.append(date)\n",
        "\n",
        "  data = {\n",
        "    'lower_bound': test_lower_bounds,\n",
        "    'upper_bound': test_upper_bounds,\n",
        "    'original': test_original_values,\n",
        "    'point_pred_mean': test_point_pred_mean,\n",
        "    'point_pred_median': test_point_pred_median,\n",
        "    'lower_upper_avg': test_lower_upper_avg,\n",
        "    'date': test_dates\n",
        "  }\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "hWu295D5gBch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_range_predictions(data):\n",
        "    df = pd.DataFrame(data)  # Ensure DataFrame format\n",
        "\n",
        "    # Coverage: Proportion of original values within bounds\n",
        "    coverage = (df['original'] >= df['lower_bound']) & (df['original'] <= df['upper_bound'])\n",
        "    coverage_pct = coverage.mean() * 100\n",
        "\n",
        "    # Average range width\n",
        "    average_range_width = df['upper_bound'] - df['lower_bound']\n",
        "    average_range_width = average_range_width.mean()\n",
        "\n",
        "    filtered_df = df[df['original'] > 0.5]  # Filter for points > 0.5\n",
        "    coverage_gt_0_5 = (filtered_df['original'] >= filtered_df['lower_bound']) & (filtered_df['original'] <= filtered_df['upper_bound'])\n",
        "    coverage_gt_0_5_pct = coverage_gt_0_5.mean() * 100\n",
        "\n",
        "    return coverage_pct, average_range_width, coverage_gt_0_5_pct\n",
        "\n",
        "def evaluate_point_predictions(data):\n",
        "    df = pd.DataFrame(data)  # Ensure DataFrame format\n",
        "\n",
        "    mse_mean = np.mean((df['original'] - df['point_pred_mean']) ** 2)\n",
        "    rmse_mean = np.sqrt(mse_mean)\n",
        "\n",
        "    # MSE and RMSE for median predictions\n",
        "    mse_median = np.mean((df['original'] - df['point_pred_median']) ** 2)\n",
        "    rmse_median = np.sqrt(mse_median)\n",
        "\n",
        "    mse_avg = np.mean((df['original'] - df['lower_upper_avg']) ** 2)\n",
        "    rmse_avg = np.sqrt(mse_avg)\n",
        "\n",
        "    # MAE for mean predictions\n",
        "    mae_mean = np.mean(np.abs(df['original'] - df['point_pred_mean']))\n",
        "\n",
        "    # MAE for median predictions\n",
        "    mae_median = np.mean(np.abs(df['original'] - df['point_pred_median']))\n",
        "\n",
        "    mae_avg = np.mean(np.abs(df['original'] - df['lower_upper_avg']))\n",
        "\n",
        "    return mse_mean, rmse_mean, mae_mean,  mse_median, rmse_median , mae_median, mse_avg, rmse_avg, mae_avg\n",
        "\n",
        "def evaluate_range_predictions_new(data):\n",
        "    df = pd.DataFrame(data)  # Ensure DataFrame format\n",
        "\n",
        "    # Coverage: Proportion of original values within bounds\n",
        "    coverage = (df['original'] >= df['lower_bound']) & (df['original'] <= df['upper_bound'])\n",
        "    coverage_pct = coverage.mean() * 100\n",
        "\n",
        "    # Average range width for different buckets\n",
        "    bins = [0, 0.13, 0.25, 0.51, 0.95, 1]  # Define your buckets\n",
        "    labels = ['0-0.13', '0.13-0.25', '0.25-0.51', '0.51-0.95', '0.95-1']\n",
        "    df['bucket'] = pd.cut(df['original'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "    average_range_widths = {}\n",
        "    for bucket in df['bucket'].unique():\n",
        "        bucket_df = df[df['bucket'] == bucket]\n",
        "        average_range_width = (bucket_df['upper_bound'] - bucket_df['lower_bound']).mean()\n",
        "        average_range_widths[bucket] = average_range_width\n",
        "\n",
        "    filtered_df = df[df['original'] > 0.5]  # Filter for points > 0.5\n",
        "    coverage_gt_0_5 = (filtered_df['original'] >= filtered_df['lower_bound']) & (filtered_df['original'] <= filtered_df['upper_bound'])\n",
        "    coverage_gt_0_5_pct = coverage_gt_0_5.mean() * 100\n",
        "\n",
        "    return coverage_pct, average_range_widths, coverage_gt_0_5_pct\n",
        "\n",
        "def evaluate_range_predictions_new_c(data):\n",
        "    df = pd.DataFrame(data)  # Ensure DataFrame format\n",
        "\n",
        "    # Coverage: Proportion of original values within bounds\n",
        "    coverage = (df['original'] >= df['lower_bound']) & (df['original'] <= df['upper_bound'])\n",
        "    coverage_pct = coverage.mean() * 100\n",
        "\n",
        "    # Average range width and coverage for different buckets\n",
        "    bins = [0, 0.13, 0.25, 0.51, 0.95, 1]  # Define your buckets\n",
        "    labels = ['0-0.13', '0.13-0.25', '0.25-0.51', '0.51-0.95', '0.95-1']\n",
        "    df['bucket'] = pd.cut(df['original'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "    average_range_widths = {}\n",
        "    coverage_percentages = {}\n",
        "    for bucket in df['bucket'].unique():\n",
        "        bucket_df = df[df['bucket'] == bucket]\n",
        "        average_range_width = (bucket_df['upper_bound'] - bucket_df['lower_bound']).mean()\n",
        "        average_range_widths[bucket] = average_range_width\n",
        "\n",
        "        # Calculate coverage for the bucket\n",
        "        bucket_coverage = ((bucket_df['original'] >= bucket_df['lower_bound']) &\n",
        "                           (bucket_df['original'] <= bucket_df['upper_bound'])).mean() * 100\n",
        "        coverage_percentages[bucket] = bucket_coverage\n",
        "\n",
        "    filtered_df = df[df['original'] > 0.5]  # Filter for points > 0.5\n",
        "    coverage_gt_0_5 = (filtered_df['original'] >= filtered_df['lower_bound']) & (filtered_df['original'] <= filtered_df['upper_bound'])\n",
        "    coverage_gt_0_5_pct = coverage_gt_0_5.mean() * 100\n",
        "\n",
        "    return coverage_pct, average_range_widths, coverage_gt_0_5_pct, coverage_percentages\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vLL0QBs_gF9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results_1(data):\n",
        "  test_coverage_pct, test_average_range_width, test_coverage_pct_gt_0_5_pct = evaluate_range_predictions(data)\n",
        "  print(f\"test Coverage: {test_coverage_pct:.4f}%\")\n",
        "  print(f\"test Average Range Width: {test_average_range_width:.4f}\")\n",
        "  print(f\"test Coverage > 0.5: {test_coverage_pct_gt_0_5_pct:.4f}%\")\n",
        "\n",
        "def print_results_2(data):\n",
        "  t_c , t_b_w , t_c_gt_0_5_pct = evaluate_range_predictions_new(data)\n",
        "  print(f\"coverage: {t_c}\")\n",
        "  print(f\"average range width: {t_b_w}\")\n",
        "  print(f\"coverage > 0.5: {t_c_gt_0_5_pct}\")\n",
        "\n",
        "def print_results_3(data):\n",
        "  t1,t2,t3,t4 = evaluate_range_predictions_new_c(data)\n",
        "  print(\"Coverage percentages per bucket\",t4)\n",
        "\n",
        "def print_point_results(data,datatype):\n",
        "  test_mse_mean, test_rmse_mean, test_mae_mean, test_mse_median, test_rmse_median, test_mae_median, test_avg_mse, test_avg_rmse, test_avg_mae = evaluate_point_predictions(data)\n",
        "  print(f\"{datatype} mse mean: {test_mse_mean:.4f}\")\n",
        "  print(f\"{datatype} rmse mean: {test_rmse_mean:.4f}\")\n",
        "  print(f\"{datatype} mae mean: {test_mae_mean:.4f}\")\n",
        "  print(f\"{datatype} mse median: {test_mse_median:.4f}\")\n",
        "  print(f\"{datatype} rmse median: {test_rmse_median:.4f}\")\n",
        "  print(f\"{datatype} mae median: {test_mae_median:.4f}\")\n",
        "  print(f\"{datatype} avg mse: {test_avg_mse:.4f}\")\n",
        "  print(f\"{datatype} avg rmse: {test_avg_rmse:.4f}\")\n",
        "  print(f\"{datatype} avg mae: {test_avg_mae:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "c33SV_PVgLIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = calculate_intervals(hdi,y_val,val_point_predictions_mean,val_point_predictions_median)"
      ],
      "metadata": {
        "id": "c2p5zynUgN3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results_1(val_data)"
      ],
      "metadata": {
        "id": "jYBAXUwrgRTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results_2(val_data)"
      ],
      "metadata": {
        "id": "MHlIrX9NgTNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results_3(val_data)"
      ],
      "metadata": {
        "id": "gNAVXQNZgVQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_point_results(val_data,\"val\")"
      ],
      "metadata": {
        "id": "VtKMClkBgXZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OdtnkMKSBrz"
      },
      "outputs": [],
      "source": [
        "def plot_graph(data,title):\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Select a random subset\n",
        "    df_plot = df.sample(n=50, random_state=41)\n",
        "\n",
        "    # Assign sequential indexes (starting from 0)\n",
        "    df_plot['index'] = range(len(df_plot))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "\n",
        "    plt.scatter(df_plot['index'], df_plot['original'], marker='o', s=100, label='Original Values')\n",
        "    # Scatter plot for median predictions\n",
        "    plt.scatter(df_plot['index'], df_plot['point_pred_median'], marker='o', s=100, label='Median Predictions', color='red')\n",
        "    plt.plot(df_plot['index'], df_plot['lower_bound'], color='lightgray', label='Lower Bound')\n",
        "    plt.plot(df_plot['index'], df_plot['upper_bound'], color='lightgray', label='Upper Bound')\n",
        "\n",
        "    # Connect upper and lower bounds with lines for clarity\n",
        "    for i in range(len(df_plot)):\n",
        "      plt.plot([df_plot['index'].iloc[i], df_plot['index'].iloc[i]],\n",
        "              [df_plot['lower_bound'].iloc[i], df_plot['upper_bound'].iloc[i]],\n",
        "              color='gray', linewidth=1)\n",
        "\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel('Fog Index Values')\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.legend()  # Add legend for clarity\n",
        "    plt.tight_layout()  # Adjust spacing for labels and title\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySV9FfYdhC3R"
      },
      "outputs": [],
      "source": [
        "plot_graph(val_data,\"Validation Data Predictions - Beta Regression (6 hrs)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cyCGcZzRD3b"
      },
      "outputs": [],
      "source": [
        "## load df_winter_test with test dataset by updating the path below\n",
        "\n",
        "df_winter_test = pd.read_csv('',index_col=0, parse_dates=True)\n",
        "\n",
        "df_winter_test = df_winter_test.dropna()\n",
        "\n",
        "# df_filtered_val = df_winter[df_winter['fog_index_6h'] != 0]\n",
        "\n",
        "X_test = df_winter_test.drop([\"fog_index_6h\"], axis=1)  # Features\n",
        "y_test = df_winter_test[\"fog_index_6h\"]  # Target variable\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxFALU_WYKnf"
      },
      "outputs": [],
      "source": [
        "X_test.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orMgzwlaRHP8"
      },
      "outputs": [],
      "source": [
        "with beta_regression_model:\n",
        "    pm.set_data({\n",
        "        'avg_air_temp': X_test_scaled_df['avg_air_temp'],\n",
        "        'avg_dew_point': X_test_scaled_df['avg_dew_point'],\n",
        "        'avg_relative_humidity': X_test_scaled_df['avg_relative_humidity'],\n",
        "        'avg_pressure': X_test_scaled_df['avg_pressure'],\n",
        "        'avg_visibility': X_test_scaled_df['avg_visibility'],\n",
        "        'energy_loss': X_test_scaled_df['energy_loss'],\n",
        "        'fog_duration': X_test_scaled_df['fog_duration'],\n",
        "        'fog_month': X_test_scaled_df['fog_month'],\n",
        "        'fog_index': y_test\n",
        "    })\n",
        "\n",
        "    idata_test = pm.sample_posterior_predictive(\n",
        "                trace,\n",
        "                var_names=[\"mu\",\"fog_index_var\"],\n",
        "                return_inferencedata=True,\n",
        "                predictions=True,\n",
        "\n",
        "                random_seed=42  # Or any seed\n",
        "     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wknqj_cXRbXF"
      },
      "outputs": [],
      "source": [
        "idata_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vh529TYuRegA"
      },
      "outputs": [],
      "source": [
        "print(idata_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEOBWlg3Ri0n"
      },
      "outputs": [],
      "source": [
        "print(idata_test.predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlwMTdyVRj5R"
      },
      "outputs": [],
      "source": [
        "predictions_for_test_point = idata_test.predictions['fog_index_var']  # Sample some draws\n",
        "\n",
        "# HDI Calculation\n",
        "hdi = pm.hdi(predictions_for_test_point, hdi_prob=0.95)\n",
        "print(hdi)\n",
        "\n",
        "hdi_90 = pm.hdi(predictions_for_test_point, hdi_prob=0.9)\n",
        "hdi_99 = pm.hdi(predictions_for_test_point, hdi_prob=0.99)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_point_predictions_mean = idata_test.predictions['fog_index_var'].mean(dim=['chain', 'draw']).values\n",
        "test_point_predictions_median = idata_test.predictions['fog_index_var'].median(dim=['chain', 'draw']).values"
      ],
      "metadata": {
        "id": "hUFibk0HP3co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_hdi_95_cal_data = calculate_intervals(hdi,y_test,test_point_predictions_mean,test_point_predictions_median)\n",
        "test_hdi_90_cal_data = calculate_intervals(hdi_90,y_test,test_point_predictions_mean,test_point_predictions_median)\n",
        "test_hdi_99_cal_data = calculate_intervals(hdi_99,y_test,test_point_predictions_mean,test_point_predictions_median)"
      ],
      "metadata": {
        "id": "Ngy1bJzdgxDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results_1(test_hdi_95_cal_data)"
      ],
      "metadata": {
        "id": "8XOXYLJRgzt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results_1(test_hdi_90_cal_data)"
      ],
      "metadata": {
        "id": "SZbkwCtug1lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results_1(test_hdi_99_cal_data)"
      ],
      "metadata": {
        "id": "2mhDlNt7g2Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results_2(test_hdi_95_cal_data)"
      ],
      "metadata": {
        "id": "M5R_Osqyg4IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results_2(test_hdi_90_cal_data)"
      ],
      "metadata": {
        "id": "W6evYDqrg6Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results_2(test_hdi_99_cal_data)"
      ],
      "metadata": {
        "id": "rQRTRvG9g8QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results_3(test_hdi_95_cal_data)"
      ],
      "metadata": {
        "id": "ICaJUF1Yg-lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results_3(test_hdi_90_cal_data)"
      ],
      "metadata": {
        "id": "5Bzz7O3bhBXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_results_3(test_hdi_99_cal_data)"
      ],
      "metadata": {
        "id": "PYCnXGOqhDQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_point_results(test_hdi_95_cal_data,\"test\")"
      ],
      "metadata": {
        "id": "I0ucAGmchNW3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}